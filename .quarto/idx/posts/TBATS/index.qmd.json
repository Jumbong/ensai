{"title":"TBATS : N'a pas de contraintes de saisonnalité","markdown":{"yaml":{"title":"TBATS : N'a pas de contraintes de saisonnalité","author":"Jumbong Junior","date":"2023-11-16","categories":["news"],"bibliography":"references.bib","notice":"@brozyna2018\n","html":{"code-fold":true},"jupyter":"python3"},"headingText":"Présentation du modèle TBATS","containsRefs":true,"markdown":"\n\nDans notre quête pour décrypter les tendances de consommation énergétique en France, tout au long de notre projet de série temporelle, nous avons été confrontés à un défi de taille : prédire efficacement la consommation future d'énergie dans un contexte de double saisonnalité. En explorant au-delà des méthodes classiques telles que les modèles SARIMA et ARIMA, nous avons rencontré des obstacles liés à l'estimation des variations saisonnières hebdomadaires et annuelles. Ces complexités nous ont conduits vers une solution innovante : le modèle TBATS.\n\nLe modèle TBATS, une avancée significative dans l'analyse des séries temporelles, embrasse la multifacette de la saisonnalité grâce à une élégante synthèse de fonctions trigonométriques. Contrairement aux modèles ARIMA et SARIMA qui peinaient à capturer les subtilités de nos données, TBATS a brillé par sa capacité à intégrer des périodicités multiples.\n\nDans cet article, nous plongeons au cœur de la méthodologie mathématique du modèle TBATS avant de le mettre en application sur nos données de consommation énergétique. Rejoignez-nous pour une exploration de la modélisation prédictive avec Python et la librairie tbats, et découvrez comment nous avons illuminé le chemin vers des prévisions énergétiques plus précises.\n\n\nLe modèle TBATS ou encore (Trigonometric, Box-Cox transform, ARMA errors, Trend and Seasonal components)[@delivera2011] a pour paramètres TBATS($\\omega$, {p,q}, $\\phi$, ${<m_1,k_1>,...,<m_n,k_n>}$) où :\n\n-   $\\omega$ correspond à la transformation de Box-Cox.\n-   {p,q} correspond aux paramètres de l'ARMA.\n-   $\\phi$ correspond à la tendance.\n-   ${<m_1,k_1>,...,<m_n,k_n>}$ correspond aux paramètres de saisonnalité.\n-   $k_1,...,k_n$ correspond aux nombres de Fourier de séries pairs.\n\nLe model s'écrit de la manière suivante :\n\n$$\ny_t(\\omega) = l_{t-1} + \\phi b_{t-1} + \\sum_{i=1}^{T} s_{t-1}(i) + \\alpha d_t\n$$ $$\nb_t = b_{t-1} + \\beta d_t\n$$ $$\ns_t(i) = \\sum_{j=1}^{k_i} s_{j,t}(i)\n$$ $$\ns_{j,t}(i) = s_{j,t-1}(i) \\cos \\lambda_j(i) + s^{*}_{j,t-1}(i) \\sin \\lambda_j(i) + \\gamma^{(i)}_1 d_t\n$$ $$\ns^{*}_{j,t}(i) = -s_{j,t-1}(i) \\sin \\lambda_j(i) + s^{*}_{j,t-1}(i) \\cos \\lambda_j(i) + \\gamma^{(i)}_2 d_t\n$$ $$\n\\lambda_j(i) = \\frac{2\\pi j}{m}\n$$\n\noù :\n\n-   $i = 1, \\ldots, T$\n-   $d_t$ est un processus ARMA ( p, q ),\n-   $\\alpha$, $\\beta$, $\\gamma_1$ et $\\gamma_2$ sont des paramètres de lissage,\n-   $l_0$ est le niveau initial,\n-   $b_0$ est la valeur de la pente.\n\nLes erreurs de prévisions seront modélisées par les indicateurs de qualité suivants :\n\n-   Mean Squared Error (MSE) : $MSE = \\frac{1}{n} \\sum_{i=1}^{n} e_i^2$\n-   Root Mean Squared Error (RMSE) : $RMSE = \\sqrt{MSE}$\n-   Mean Absolute Error (MAE) : $MAE = \\frac{1}{n} \\sum_{i=1}^{n} |e_i|$\n-   Mean Absolute Percentage Error (MAPE) : $MAPE = \\frac{1}{n} \\sum_{i=1}^{n} \\left| \\frac{e_i}{y_i} \\right| \\cdot 100\\%$\n-   Mean Error (ME) : $ME = \\frac{1}{n} \\sum_{i=1}^{n} e_i$\n-   Mean Percentage Error (MPE) : $MPE = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{e_i}{y_i} \\cdot 100\\% $\n-   Mean Absolute Scaled Error (MASE): $MASE = \\frac{n}{n-m} \\frac{\\sum_{i=1}^{n} |e_i|}{\\sum_{i=m+1}^{n} |y_i - y_{i-m}|}$\n-   Autocorrelation function of errors at lag 1 (ACF1) : $ACF1 = \\frac{\\sum_{i=1}^{n-1} (e_i - ME) \\cdot (e_{i+1} - ME)}{\\sum_{i=1}^{n} (e_i - ME)^2}$\n\noù : $e_t$ is the error $e_t = y_t -{ y_t}^*$\n\n$y_t$ est la valeur actuelle, $y_t^*$ est la valeur prédicte , m est la période de saisonalité.\n\nDans l'analyse des prédictions de modèles statistiques, la compréhension des erreurs est cruciale. En comparant le Mean Error (ME) et le Mean Absolute Error (MAE), nous pouvons déterminer si les valeurs prédites sont systématiquement plus élevées ou plus faibles que les valeurs réelles, indiquant un biais directionnel. De même, la comparaison entre le Mean Percentage Error (MPE) et le Mean Absolute Percentage Error (MAPE) révèle l'ampleur de ce biais en termes de pourcentage.\n\nMais ce n'est pas tout. L'analyse du Mean Squared Error (MSE) peut révéler la présence de valeurs aberrantes ou d'erreurs exceptionnellement élevées dans les prédictions. Ces erreurs extrêmes se manifestent souvent par un écart significatif entre le MAE et le Root Mean Squared Error (RMSE), où le RMSE, en donnant plus de poids aux grandes erreurs, met en lumière les défauts plus subtils de notre modèle prédictif.\n\n# Présentation des données\n\nDans notre étude appronfondie sur la demande énergétique en france, nous avons plongé au coeur des données de consommation, mésurées en mégawattts, révelatrices des tendances de consommation du pays. Afin d'affiner notre analyse nous avons présenter les données sous forme de séries temporelles journalières. Cette approche nous permettra d'aborder plus aisement l'analyse.\n\n# Le dendogramme de la série temporelle\n\nNous avons mis en évidence des motifs saisonniers clés à travers la représentation d'un dendogramme. Cet outil permettra de vérifier que 365 et 7 sont des saisonnalités.\n\n```{python}\n#| eval: false\nfrom scipy import signal\n\nfrequencies, power_spectral_density = signal.periodogram(df_con_daily['consommation'].values)\n\n\n# Tracé du périodogramme\nplt.figure(figsize=(5, 3))\nplt.plot(frequencies, power_spectral_density)\nplt.title('Périodogramme')\nplt.xlabel('Fréquence')\nplt.ylabel('Densité spectrale de puissance')\n\n# Ajout de la ligne verticale à 1/12\nplt.axvline(x=1/365, color='red', linestyle='--')\nplt.axvline(x=1/7, color='yellow', linestyle='--')\n\nplt.show()\n```\n\n![dendrogramme](dendogramme.png)\n\nNous observons que les cylces de 365 et 7 se détachent nettement, mettant en évidence une saisonnalité annuelle est hebdommadaire.\n\nEn plus de l'analyse dendrogramme, une autre méthode efficace pour mettre en lumière les saisonnalités dans nos données énergétiques consiste à décomposer la série temporelle. Cette approche permet d'isoler et d'examiner les composantes saisonnières annuelles et hebdomadaires de manière distincte. L'analyse des fonctions d'autocorrélation et d'autocorrélation partielle offre également des insights précieux. Cependant, pour rester concentrés sur les aspects les plus pertinents de notre étude, nous choisirons de ne pas approfondir cette méthode dans ce cadre. Les paramètres du model TBATS(False,{0,0},0.85,{\\<7,365\\>}) correspondent au mieux aux données.\n\nDans notre démarche analytique, une étape cruciale a été la segmentation de nos données en ensembles d'entraînement et de test. Cette division stratégique est essentielle pour affiner et évaluer la précision de nos modèles prédictifs. La variable **date_cutoff** joue un rôle clé dans ce processus, définissant le point de séparation entre les périodes d'entraînement et de test.\n\n```{python}\n#| eval: false\n\nimport pandas as pd\nfrom sktime.datatypes import check_raise\nfrom datetime import datetime\n\ny = df_con_daily['consommation']\ny.index = pd.to_datetime(y.index)\n\n\n\ndate_cutoff = pd.Timestamp('2019-12-31')\n\n# Ensuite, effectuez la comparaison\ny_train = df_con_daily[df_con_daily.index < date_cutoff]['consommation']\ny_test = df_con_daily[df_con_daily.index >= date_cutoff]['consommation']\ny_train.index = pd.to_datetime(y_train.index)\n\n```\n\nEnsuite nous avons instancier le modèle TBATS avec les différentes saisonnalités 7 et 365. n_jobs facilite le temps de computation. Pour plus de détails voir \\[TBATS\\](<https://www.sktime.net/en/latest/api_reference/auto_generated/sktime.forecasting.tbats.TBATS.html>). Assurez vous que vos index ou la colonne date soit de type **pandas.core.indexes.datetimes.DatetimeIndex**. Pour cela vous pouvez vous servir de chatgpt.\n\n```{python}\n#| eval: false\nforecaster = TBATS(sp = [7, 365], n_jobs = 1)\nmodel = forecaster.fit(y_train)\n\n# Prediction\nfh = len(y_test)\ny_pred = model.forecast(fh)\n\nfig, ax = plt.subplots(figsize = (15,5))  \ny.plot(title = 'TBATS dayly energie consumption', xlabel = '', ax = ax)\ny_pred.plot(ax = ax)\nax.legend(['Actual Values', 'Forecast'])\nplt.show()\n```\n\nUne fonction pour les différentes métriques pour évaluer la qualité du modèle est donnée par :\n\n![prevision](prevision.png)\n\n```{python}\n\n#| eval: false\ndef print_metrics(y_true, y_pred, model_name):\n    mae_ = mean_absolute_error(y_true, y_pred)\n    rmse_ = np.sqrt(mean_squared_error(y_true, y_pred))\n    mape_ = mean_absolute_percentage_error(y_true, y_pred)\n    smape_ = mean_absolute_percentage_error(y_true, y_pred, symmetric = True)\n    \n    dict_ = {'MAE': mae_, 'RMSE': rmse_,\n             'MAPE': mape_, 'SMAPE': smape_ }\n    \n    df = pd.DataFrame(dict_, index = [model_name])\n    return(df.round(decimals = 2)) \n```\n\nPour avoir les résultats des performances du modèle, il faut exécuter cette fonction.\n\n```{python}\n#| eval: false\nprint_metrics(y_test, y_pred, 'TBATS Forecaster')\n```\n\n# Résultats de Prévision avec TBATS\n\nNous avons essayer de mettre les résultats dans un tableau :\n\n```{python}\n\n#| label: indicateurs\n#| tbl-cap: Indicateurs de performance\n\nfrom IPython.display import Markdown\nfrom tabulate import tabulate \n\ntable = [[\"TBATS Forecaster\",\"290.94\",\"412.76\",\"0.07\",\"0.06\"]]\n\nMarkdown((tabulate(\n    table,\n    headers = [\"\",\"MAE\",\"RMSE\",\"MAPE\",\"SMAPE\"]\n)\n))\n```\n\n# Conclusion\n\n-   Le Mean Absolute Error (MAE) : Il montre qu'en moyenne, les prévisions s'écartent de 290.94 unités des valeurs réelles, nous donnant une idée de l'erreur moyenne absolue.\n-   Le Root Mean Squared Error (RMSE) : Sa valeur de  493.17, n'étant pas très élévée comparé au MAE, nous pouvons conclure que les erreurs de prévision sont relativement faibles.\n-   Le Mean Absolute Percentage Error (MAPE) et le Symmetric Mean Absolute Percentage Error (SMAPE) : Ils indiquent une erreur moyenne de prédiction de 0.07\\%, ce qui est considéré comme relativement précis dans notre contexte.\n\nAinsi le modèle TBATS est un modèle qui permet de faire des prévisions acceptables sur les données possèdant des saisonnalités multiples.\n\n### References\n\n::: {#refs}\n:::","srcMarkdownNoYaml":"\n\nDans notre quête pour décrypter les tendances de consommation énergétique en France, tout au long de notre projet de série temporelle, nous avons été confrontés à un défi de taille : prédire efficacement la consommation future d'énergie dans un contexte de double saisonnalité. En explorant au-delà des méthodes classiques telles que les modèles SARIMA et ARIMA, nous avons rencontré des obstacles liés à l'estimation des variations saisonnières hebdomadaires et annuelles. Ces complexités nous ont conduits vers une solution innovante : le modèle TBATS.\n\nLe modèle TBATS, une avancée significative dans l'analyse des séries temporelles, embrasse la multifacette de la saisonnalité grâce à une élégante synthèse de fonctions trigonométriques. Contrairement aux modèles ARIMA et SARIMA qui peinaient à capturer les subtilités de nos données, TBATS a brillé par sa capacité à intégrer des périodicités multiples.\n\nDans cet article, nous plongeons au cœur de la méthodologie mathématique du modèle TBATS avant de le mettre en application sur nos données de consommation énergétique. Rejoignez-nous pour une exploration de la modélisation prédictive avec Python et la librairie tbats, et découvrez comment nous avons illuminé le chemin vers des prévisions énergétiques plus précises.\n\n# Présentation du modèle TBATS\n\nLe modèle TBATS ou encore (Trigonometric, Box-Cox transform, ARMA errors, Trend and Seasonal components)[@delivera2011] a pour paramètres TBATS($\\omega$, {p,q}, $\\phi$, ${<m_1,k_1>,...,<m_n,k_n>}$) où :\n\n-   $\\omega$ correspond à la transformation de Box-Cox.\n-   {p,q} correspond aux paramètres de l'ARMA.\n-   $\\phi$ correspond à la tendance.\n-   ${<m_1,k_1>,...,<m_n,k_n>}$ correspond aux paramètres de saisonnalité.\n-   $k_1,...,k_n$ correspond aux nombres de Fourier de séries pairs.\n\nLe model s'écrit de la manière suivante :\n\n$$\ny_t(\\omega) = l_{t-1} + \\phi b_{t-1} + \\sum_{i=1}^{T} s_{t-1}(i) + \\alpha d_t\n$$ $$\nb_t = b_{t-1} + \\beta d_t\n$$ $$\ns_t(i) = \\sum_{j=1}^{k_i} s_{j,t}(i)\n$$ $$\ns_{j,t}(i) = s_{j,t-1}(i) \\cos \\lambda_j(i) + s^{*}_{j,t-1}(i) \\sin \\lambda_j(i) + \\gamma^{(i)}_1 d_t\n$$ $$\ns^{*}_{j,t}(i) = -s_{j,t-1}(i) \\sin \\lambda_j(i) + s^{*}_{j,t-1}(i) \\cos \\lambda_j(i) + \\gamma^{(i)}_2 d_t\n$$ $$\n\\lambda_j(i) = \\frac{2\\pi j}{m}\n$$\n\noù :\n\n-   $i = 1, \\ldots, T$\n-   $d_t$ est un processus ARMA ( p, q ),\n-   $\\alpha$, $\\beta$, $\\gamma_1$ et $\\gamma_2$ sont des paramètres de lissage,\n-   $l_0$ est le niveau initial,\n-   $b_0$ est la valeur de la pente.\n\nLes erreurs de prévisions seront modélisées par les indicateurs de qualité suivants :\n\n-   Mean Squared Error (MSE) : $MSE = \\frac{1}{n} \\sum_{i=1}^{n} e_i^2$\n-   Root Mean Squared Error (RMSE) : $RMSE = \\sqrt{MSE}$\n-   Mean Absolute Error (MAE) : $MAE = \\frac{1}{n} \\sum_{i=1}^{n} |e_i|$\n-   Mean Absolute Percentage Error (MAPE) : $MAPE = \\frac{1}{n} \\sum_{i=1}^{n} \\left| \\frac{e_i}{y_i} \\right| \\cdot 100\\%$\n-   Mean Error (ME) : $ME = \\frac{1}{n} \\sum_{i=1}^{n} e_i$\n-   Mean Percentage Error (MPE) : $MPE = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{e_i}{y_i} \\cdot 100\\% $\n-   Mean Absolute Scaled Error (MASE): $MASE = \\frac{n}{n-m} \\frac{\\sum_{i=1}^{n} |e_i|}{\\sum_{i=m+1}^{n} |y_i - y_{i-m}|}$\n-   Autocorrelation function of errors at lag 1 (ACF1) : $ACF1 = \\frac{\\sum_{i=1}^{n-1} (e_i - ME) \\cdot (e_{i+1} - ME)}{\\sum_{i=1}^{n} (e_i - ME)^2}$\n\noù : $e_t$ is the error $e_t = y_t -{ y_t}^*$\n\n$y_t$ est la valeur actuelle, $y_t^*$ est la valeur prédicte , m est la période de saisonalité.\n\nDans l'analyse des prédictions de modèles statistiques, la compréhension des erreurs est cruciale. En comparant le Mean Error (ME) et le Mean Absolute Error (MAE), nous pouvons déterminer si les valeurs prédites sont systématiquement plus élevées ou plus faibles que les valeurs réelles, indiquant un biais directionnel. De même, la comparaison entre le Mean Percentage Error (MPE) et le Mean Absolute Percentage Error (MAPE) révèle l'ampleur de ce biais en termes de pourcentage.\n\nMais ce n'est pas tout. L'analyse du Mean Squared Error (MSE) peut révéler la présence de valeurs aberrantes ou d'erreurs exceptionnellement élevées dans les prédictions. Ces erreurs extrêmes se manifestent souvent par un écart significatif entre le MAE et le Root Mean Squared Error (RMSE), où le RMSE, en donnant plus de poids aux grandes erreurs, met en lumière les défauts plus subtils de notre modèle prédictif.\n\n# Présentation des données\n\nDans notre étude appronfondie sur la demande énergétique en france, nous avons plongé au coeur des données de consommation, mésurées en mégawattts, révelatrices des tendances de consommation du pays. Afin d'affiner notre analyse nous avons présenter les données sous forme de séries temporelles journalières. Cette approche nous permettra d'aborder plus aisement l'analyse.\n\n# Le dendogramme de la série temporelle\n\nNous avons mis en évidence des motifs saisonniers clés à travers la représentation d'un dendogramme. Cet outil permettra de vérifier que 365 et 7 sont des saisonnalités.\n\n```{python}\n#| eval: false\nfrom scipy import signal\n\nfrequencies, power_spectral_density = signal.periodogram(df_con_daily['consommation'].values)\n\n\n# Tracé du périodogramme\nplt.figure(figsize=(5, 3))\nplt.plot(frequencies, power_spectral_density)\nplt.title('Périodogramme')\nplt.xlabel('Fréquence')\nplt.ylabel('Densité spectrale de puissance')\n\n# Ajout de la ligne verticale à 1/12\nplt.axvline(x=1/365, color='red', linestyle='--')\nplt.axvline(x=1/7, color='yellow', linestyle='--')\n\nplt.show()\n```\n\n![dendrogramme](dendogramme.png)\n\nNous observons que les cylces de 365 et 7 se détachent nettement, mettant en évidence une saisonnalité annuelle est hebdommadaire.\n\nEn plus de l'analyse dendrogramme, une autre méthode efficace pour mettre en lumière les saisonnalités dans nos données énergétiques consiste à décomposer la série temporelle. Cette approche permet d'isoler et d'examiner les composantes saisonnières annuelles et hebdomadaires de manière distincte. L'analyse des fonctions d'autocorrélation et d'autocorrélation partielle offre également des insights précieux. Cependant, pour rester concentrés sur les aspects les plus pertinents de notre étude, nous choisirons de ne pas approfondir cette méthode dans ce cadre. Les paramètres du model TBATS(False,{0,0},0.85,{\\<7,365\\>}) correspondent au mieux aux données.\n\nDans notre démarche analytique, une étape cruciale a été la segmentation de nos données en ensembles d'entraînement et de test. Cette division stratégique est essentielle pour affiner et évaluer la précision de nos modèles prédictifs. La variable **date_cutoff** joue un rôle clé dans ce processus, définissant le point de séparation entre les périodes d'entraînement et de test.\n\n```{python}\n#| eval: false\n\nimport pandas as pd\nfrom sktime.datatypes import check_raise\nfrom datetime import datetime\n\ny = df_con_daily['consommation']\ny.index = pd.to_datetime(y.index)\n\n\n\ndate_cutoff = pd.Timestamp('2019-12-31')\n\n# Ensuite, effectuez la comparaison\ny_train = df_con_daily[df_con_daily.index < date_cutoff]['consommation']\ny_test = df_con_daily[df_con_daily.index >= date_cutoff]['consommation']\ny_train.index = pd.to_datetime(y_train.index)\n\n```\n\nEnsuite nous avons instancier le modèle TBATS avec les différentes saisonnalités 7 et 365. n_jobs facilite le temps de computation. Pour plus de détails voir \\[TBATS\\](<https://www.sktime.net/en/latest/api_reference/auto_generated/sktime.forecasting.tbats.TBATS.html>). Assurez vous que vos index ou la colonne date soit de type **pandas.core.indexes.datetimes.DatetimeIndex**. Pour cela vous pouvez vous servir de chatgpt.\n\n```{python}\n#| eval: false\nforecaster = TBATS(sp = [7, 365], n_jobs = 1)\nmodel = forecaster.fit(y_train)\n\n# Prediction\nfh = len(y_test)\ny_pred = model.forecast(fh)\n\nfig, ax = plt.subplots(figsize = (15,5))  \ny.plot(title = 'TBATS dayly energie consumption', xlabel = '', ax = ax)\ny_pred.plot(ax = ax)\nax.legend(['Actual Values', 'Forecast'])\nplt.show()\n```\n\nUne fonction pour les différentes métriques pour évaluer la qualité du modèle est donnée par :\n\n![prevision](prevision.png)\n\n```{python}\n\n#| eval: false\ndef print_metrics(y_true, y_pred, model_name):\n    mae_ = mean_absolute_error(y_true, y_pred)\n    rmse_ = np.sqrt(mean_squared_error(y_true, y_pred))\n    mape_ = mean_absolute_percentage_error(y_true, y_pred)\n    smape_ = mean_absolute_percentage_error(y_true, y_pred, symmetric = True)\n    \n    dict_ = {'MAE': mae_, 'RMSE': rmse_,\n             'MAPE': mape_, 'SMAPE': smape_ }\n    \n    df = pd.DataFrame(dict_, index = [model_name])\n    return(df.round(decimals = 2)) \n```\n\nPour avoir les résultats des performances du modèle, il faut exécuter cette fonction.\n\n```{python}\n#| eval: false\nprint_metrics(y_test, y_pred, 'TBATS Forecaster')\n```\n\n# Résultats de Prévision avec TBATS\n\nNous avons essayer de mettre les résultats dans un tableau :\n\n```{python}\n\n#| label: indicateurs\n#| tbl-cap: Indicateurs de performance\n\nfrom IPython.display import Markdown\nfrom tabulate import tabulate \n\ntable = [[\"TBATS Forecaster\",\"290.94\",\"412.76\",\"0.07\",\"0.06\"]]\n\nMarkdown((tabulate(\n    table,\n    headers = [\"\",\"MAE\",\"RMSE\",\"MAPE\",\"SMAPE\"]\n)\n))\n```\n\n# Conclusion\n\n-   Le Mean Absolute Error (MAE) : Il montre qu'en moyenne, les prévisions s'écartent de 290.94 unités des valeurs réelles, nous donnant une idée de l'erreur moyenne absolue.\n-   Le Root Mean Squared Error (RMSE) : Sa valeur de  493.17, n'étant pas très élévée comparé au MAE, nous pouvons conclure que les erreurs de prévision sont relativement faibles.\n-   Le Mean Absolute Percentage Error (MAPE) et le Symmetric Mean Absolute Percentage Error (SMAPE) : Ils indiquent une erreur moyenne de prédiction de 0.07\\%, ce qui est considéré comme relativement précis dans notre contexte.\n\nAinsi le modèle TBATS est un modèle qui permet de faire des prévisions acceptables sur les données possèdant des saisonnalités multiples.\n\n### References\n\n::: {#refs}\n:::"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"cosmo","title-block-banner":true,"title":"TBATS : N'a pas de contraintes de saisonnalité","author":"Jumbong Junior","date":"2023-11-16","categories":["news"],"bibliography":["references.bib"],"notice":"@brozyna2018\n","html":{"code-fold":true},"jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}