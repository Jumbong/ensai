{
  "hash": "31a52c23606e216a7b72d861a02d9123",
  "result": {
    "markdown": "---\ntitle: \"Examen de machine learning\"\nauthor: \"Jumbong Junior\"\ndate: \"2023-12-08\"\ncategories: [news]\n---\n\n# Introduction\n\nJe ne sais pas si c'est Da Veiga qui vous donnera cours, mais je vais vous donner un petit aperçu de ce que vous pourriez avoir comme examen. Je pense que c'est important parce que nous prenons souvent à la légère ce genre d'activité surtout qu'il permet l'utilisation des générateurs de texte(chatgpt). Cette année, peu d'étudiant ont terminé le projet, parce que chargé les données était long et fastidieux. Je vous conseille de vous y prendre à l'avance. Créer des fonctions qui font certaines tâches, je vous expliquerai progressivement.\n\n# Les données\n\nJ'utiliserai un échantillon des données(Dataset1 et Dataset2) proposé par l'enseignant sur ma machine locale afin que la compilation soit plus rapide. Je mettrai les données sur mon github.\n\n# Packages\n\nJ'utiliserai les packages suivants: sklearn, pandas, numpy, matplotlib,seaborn pour la visualiation. \n\n# Objectif\n\nL'objectif de ce notebook consistera à une 'analyse exploratoire des données, le prétraitement des données pour la modélisation, et l'application ainsi que l'évaluation de modèles de classification() sur un ensemble de données.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# Importation des packages\n\nimport pandas as pd\nimport numpy as np\nimport pandas as pd\nimport chardet\nimport warnings\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.feature_selection import mutual_info_classif\n\nfrom sklearn.feature_selection import mutual_info_classif\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n```\n:::\n\n\n# Chargement des données\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nwith open('Dataset1.csv', 'rb') as f:\n    result = chardet.detect(f.read())  # or readline if the file is large\n#print(result['encoding'])\n\nDataset1 = pd.read_csv('Dataset1.csv', delimiter=\",\",decimal = \".\",encoding=result['encoding'])\nDataset1.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Vegetation_Type_2</th>\n      <th>Groundwater_Level_1</th>\n      <th>Drainage_Quality_1</th>\n      <th>Slope</th>\n      <th>Hillshade_9am</th>\n      <th>Hillshade_Noon</th>\n      <th>Pollution_Level_1</th>\n      <th>Water_Source_Distance_2</th>\n      <th>Terrain_Roughness_2</th>\n      <th>Urban_Proximity_Index_1</th>\n      <th>...</th>\n      <th>Soil_Moisture_Level_2</th>\n      <th>Horizontal_Distance_To_Hydrology</th>\n      <th>Wind_Speed_Average_2</th>\n      <th>Elevation_Range_1</th>\n      <th>Pollution_Level_2</th>\n      <th>Vegetation_Type_1</th>\n      <th>Temperature_Average_1</th>\n      <th>Canopy_Cover_2</th>\n      <th>Elevation</th>\n      <th>Cover_Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>450.684968</td>\n      <td>2054.426315</td>\n      <td>229.994980</td>\n      <td>3</td>\n      <td>221</td>\n      <td>232</td>\n      <td>181.000000</td>\n      <td>227.161401</td>\n      <td>216.000000</td>\n      <td>14.0</td>\n      <td>...</td>\n      <td>418.375833</td>\n      <td>258</td>\n      <td>116.000000</td>\n      <td>219.000000</td>\n      <td>224.000000</td>\n      <td>0.000000</td>\n      <td>9.000000</td>\n      <td>503.586301</td>\n      <td>2596</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>889.885392</td>\n      <td>997.573983</td>\n      <td>208.000000</td>\n      <td>2</td>\n      <td>220</td>\n      <td>235</td>\n      <td>166.000000</td>\n      <td>933.851870</td>\n      <td>251.000000</td>\n      <td>16.0</td>\n      <td>...</td>\n      <td>2488.726342</td>\n      <td>212</td>\n      <td>179.025367</td>\n      <td>236.000000</td>\n      <td>224.000000</td>\n      <td>69.000000</td>\n      <td>17.000000</td>\n      <td>537.000000</td>\n      <td>2590</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1232.738700</td>\n      <td>676.352745</td>\n      <td>214.313227</td>\n      <td>9</td>\n      <td>234</td>\n      <td>238</td>\n      <td>205.000000</td>\n      <td>4235.282432</td>\n      <td>176.898683</td>\n      <td>13.0</td>\n      <td>...</td>\n      <td>1852.423116</td>\n      <td>268</td>\n      <td>156.000000</td>\n      <td>200.872578</td>\n      <td>230.415218</td>\n      <td>120.357544</td>\n      <td>10.000000</td>\n      <td>376.000000</td>\n      <td>2804</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3359.512595</td>\n      <td>4720.481538</td>\n      <td>230.000000</td>\n      <td>18</td>\n      <td>238</td>\n      <td>238</td>\n      <td>176.002696</td>\n      <td>1066.935784</td>\n      <td>220.000000</td>\n      <td>11.0</td>\n      <td>...</td>\n      <td>5388.528248</td>\n      <td>242</td>\n      <td>156.000000</td>\n      <td>230.000000</td>\n      <td>243.000000</td>\n      <td>15.000000</td>\n      <td>12.933234</td>\n      <td>30.000000</td>\n      <td>2785</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1907.275049</td>\n      <td>2187.627994</td>\n      <td>221.000000</td>\n      <td>2</td>\n      <td>220</td>\n      <td>234</td>\n      <td>109.000000</td>\n      <td>1182.489702</td>\n      <td>184.859965</td>\n      <td>9.0</td>\n      <td>...</td>\n      <td>304.080537</td>\n      <td>153</td>\n      <td>112.000000</td>\n      <td>232.000000</td>\n      <td>213.000000</td>\n      <td>39.000000</td>\n      <td>14.000000</td>\n      <td>330.000000</td>\n      <td>2595</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 51 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n#info\nDataset1.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 581012 entries, 0 to 581011\nData columns (total 51 columns):\n #   Column                              Non-Null Count   Dtype  \n---  ------                              --------------   -----  \n 0   Vegetation_Type_2                   581012 non-null  float64\n 1   Groundwater_Level_1                 581012 non-null  float64\n 2   Drainage_Quality_1                  581012 non-null  float64\n 3   Slope                               581012 non-null  int64  \n 4   Hillshade_9am                       581012 non-null  int64  \n 5   Hillshade_Noon                      581012 non-null  int64  \n 6   Pollution_Level_1                   581012 non-null  float64\n 7   Water_Source_Distance_2             581012 non-null  float64\n 8   Terrain_Roughness_2                 581012 non-null  float64\n 9   Urban_Proximity_Index_1             581012 non-null  float64\n 10  Sunlight_Intensity_2                581012 non-null  float64\n 11  Rainfall_Index_1                    581012 non-null  float64\n 12  Canopy_Cover_1                      581012 non-null  float64\n 13  Rock_Type_2                         581012 non-null  float64\n 14  Rainfall_Index_2                    581012 non-null  float64\n 15  Terrain_Slope_Angle_2               581012 non-null  float64\n 16  Temperature_Average_2               581012 non-null  float64\n 17  Air_Quality_Index_1                 581012 non-null  float64\n 18  Horizontal_Distance_To_Roadways     581012 non-null  int64  \n 19  Soil_Mineral_Content_2              581012 non-null  float64\n 20  Wildlife_Density_2                  581012 non-null  float64\n 21  Water_Source_Distance_1             581012 non-null  float64\n 22  Air_Quality_Index_2                 581012 non-null  float64\n 23  Wildlife_Density_1                  581012 non-null  float64\n 24  Drainage_Quality_2                  581012 non-null  float64\n 25  Land_Use_Category_2                 581012 non-null  float64\n 26  Groundwater_Level_2                 581012 non-null  float64\n 27  Wind_Speed_Average_1                581012 non-null  float64\n 28  Hillshade_3pm                       581012 non-null  int64  \n 29  Terrain_Slope_Angle_1               581012 non-null  float64\n 30  Land_Use_Category_1                 581012 non-null  float64\n 31  Elevation_Range_2                   581012 non-null  float64\n 32  Vertical_Distance_To_Hydrology      581012 non-null  int64  \n 33  Urban_Proximity_Index_2             581012 non-null  float64\n 34  Horizontal_Distance_To_Fire_Points  581012 non-null  int64  \n 35  Soil_Mineral_Content_1              581012 non-null  float64\n 36  Aspect                              581012 non-null  int64  \n 37  Soil_Moisture_Level_1               581012 non-null  float64\n 38  Terrain_Roughness_1                 581012 non-null  float64\n 39  Rock_Type_1                         581012 non-null  float64\n 40  Sunlight_Intensity_1                581012 non-null  float64\n 41  Soil_Moisture_Level_2               581012 non-null  float64\n 42  Horizontal_Distance_To_Hydrology    581012 non-null  int64  \n 43  Wind_Speed_Average_2                581012 non-null  float64\n 44  Elevation_Range_1                   581012 non-null  float64\n 45  Pollution_Level_2                   581012 non-null  float64\n 46  Vegetation_Type_1                   581012 non-null  float64\n 47  Temperature_Average_1               581012 non-null  float64\n 48  Canopy_Cover_2                      581012 non-null  float64\n 49  Elevation                           581012 non-null  int64  \n 50  Cover_Type                          581012 non-null  int64  \ndtypes: float64(40), int64(11)\nmemory usage: 226.1 MB\n```\n:::\n:::\n\n\nLes données contiennent 51 colonnes et 581012 lignes.\nDans le code ci-dessous, nous allons séparer les données en output(Y) et en features(X). L'output ici est la variable **Cover_Type**.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n # split  data into training and testing sets\nX = Dataset1.drop(['Cover_Type'], axis=1).copy()\nY = Dataset1['Cover_Type'].copy()\n```\n:::\n\n\nLa prémiere chose à faire est de voir la distribution de Y. Afin de vérifier si c'est une variable catégorielle ou continue.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# Distribution de Y\nsns.countplot(x='Cover_Type', data=Dataset1)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-1.png){width=618 height=429}\n:::\n:::\n\n\nOn peut voir que la variable est catégorielle. Elle contient 7 classes non équilibrées. On peut s'attendre que le modèle prédira mieux les classes les plus représentées(1 et 2) que les autres.\n\nNous ne traiterons pas ça ici. Les données étant labélisées, nous allons utiliser des modèles de classification.\n\n# Data preprocessing\n\nNous pouvons dans un premier temps vérifier s'il y a des valeurs manquantes dans les données.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# Missing values\nDataset1.isnull().sum()\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nVegetation_Type_2                     0\nGroundwater_Level_1                   0\nDrainage_Quality_1                    0\nSlope                                 0\nHillshade_9am                         0\nHillshade_Noon                        0\nPollution_Level_1                     0\nWater_Source_Distance_2               0\nTerrain_Roughness_2                   0\nUrban_Proximity_Index_1               0\nSunlight_Intensity_2                  0\nRainfall_Index_1                      0\nCanopy_Cover_1                        0\nRock_Type_2                           0\nRainfall_Index_2                      0\nTerrain_Slope_Angle_2                 0\nTemperature_Average_2                 0\nAir_Quality_Index_1                   0\nHorizontal_Distance_To_Roadways       0\nSoil_Mineral_Content_2                0\nWildlife_Density_2                    0\nWater_Source_Distance_1               0\nAir_Quality_Index_2                   0\nWildlife_Density_1                    0\nDrainage_Quality_2                    0\nLand_Use_Category_2                   0\nGroundwater_Level_2                   0\nWind_Speed_Average_1                  0\nHillshade_3pm                         0\nTerrain_Slope_Angle_1                 0\nLand_Use_Category_1                   0\nElevation_Range_2                     0\nVertical_Distance_To_Hydrology        0\nUrban_Proximity_Index_2               0\nHorizontal_Distance_To_Fire_Points    0\nSoil_Mineral_Content_1                0\nAspect                                0\nSoil_Moisture_Level_1                 0\nTerrain_Roughness_1                   0\nRock_Type_1                           0\nSunlight_Intensity_1                  0\nSoil_Moisture_Level_2                 0\nHorizontal_Distance_To_Hydrology      0\nWind_Speed_Average_2                  0\nElevation_Range_1                     0\nPollution_Level_2                     0\nVegetation_Type_1                     0\nTemperature_Average_1                 0\nCanopy_Cover_2                        0\nElevation                             0\nCover_Type                            0\ndtype: int64\n```\n:::\n:::\n\n\nIl n'y a pas de valeurs manquantes dans les données. \n\n# Features selections.\n\nNous allons supprimer les variables en se basant sur le critère de [l'information mutulle](https://fr.wikipedia.org/wiki/Information_mutuelle) qui n'apportent pas au moins 0.01 d'information à la variable cible.\n\nEn termes simples, l'information mutuelle mesure combien la connaissance d'une variable réduit l'incertitude concernant l'autre. \n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nmutual_info = mutual_info_classif(X, Y)\n\n\nmutual_info_df = pd.DataFrame(mutual_info, index=X.columns, columns=['Mutual Information'])\n\n# Filtrer les caractéristiques avec une information mutuelle supérieure à 0.01\nrelevant_features = mutual_info_df[mutual_info_df['Mutual Information'] > 0.01].index\n\n# Afficher les caractéristiques pertinentes\nprint(\"Caractéristiques pertinentes (Information Mutuelle > 0.01) :\")\nprint(relevant_features)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCaractéristiques pertinentes (Information Mutuelle > 0.01) :\nIndex(['Slope', 'Hillshade_9am', 'Hillshade_Noon',\n       'Horizontal_Distance_To_Roadways', 'Hillshade_3pm',\n       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Fire_Points',\n       'Aspect', 'Horizontal_Distance_To_Hydrology', 'Elevation'],\n      dtype='object')\n```\n:::\n:::\n\n\nNous allons supprimer les variables qui ne sont pas pertinentes.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# Supprimer les caractéristiques non pertinentes\nX = X[relevant_features]\nX.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 581012 entries, 0 to 581011\nData columns (total 10 columns):\n #   Column                              Non-Null Count   Dtype\n---  ------                              --------------   -----\n 0   Slope                               581012 non-null  int64\n 1   Hillshade_9am                       581012 non-null  int64\n 2   Hillshade_Noon                      581012 non-null  int64\n 3   Horizontal_Distance_To_Roadways     581012 non-null  int64\n 4   Hillshade_3pm                       581012 non-null  int64\n 5   Vertical_Distance_To_Hydrology      581012 non-null  int64\n 6   Horizontal_Distance_To_Fire_Points  581012 non-null  int64\n 7   Aspect                              581012 non-null  int64\n 8   Horizontal_Distance_To_Hydrology    581012 non-null  int64\n 9   Elevation                           581012 non-null  int64\ndtypes: int64(10)\nmemory usage: 44.3 MB\n```\n:::\n:::\n\n\nLà on a plus que 10 features et les données sont toutes numériques. \n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nX.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Slope</th>\n      <th>Hillshade_9am</th>\n      <th>Hillshade_Noon</th>\n      <th>Horizontal_Distance_To_Roadways</th>\n      <th>Hillshade_3pm</th>\n      <th>Vertical_Distance_To_Hydrology</th>\n      <th>Horizontal_Distance_To_Fire_Points</th>\n      <th>Aspect</th>\n      <th>Horizontal_Distance_To_Hydrology</th>\n      <th>Elevation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>581012.000000</td>\n      <td>581012.000000</td>\n      <td>581012.000000</td>\n      <td>581012.000000</td>\n      <td>581012.000000</td>\n      <td>581012.000000</td>\n      <td>581012.000000</td>\n      <td>581012.000000</td>\n      <td>581012.000000</td>\n      <td>581012.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>14.103704</td>\n      <td>212.146049</td>\n      <td>223.318716</td>\n      <td>2350.146611</td>\n      <td>142.528263</td>\n      <td>46.418855</td>\n      <td>1980.291226</td>\n      <td>155.656807</td>\n      <td>269.428217</td>\n      <td>2959.365301</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>7.488242</td>\n      <td>26.769889</td>\n      <td>19.768697</td>\n      <td>1559.254870</td>\n      <td>38.274529</td>\n      <td>58.295232</td>\n      <td>1324.195210</td>\n      <td>111.913721</td>\n      <td>212.549356</td>\n      <td>279.984734</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-173.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1859.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>9.000000</td>\n      <td>198.000000</td>\n      <td>213.000000</td>\n      <td>1106.000000</td>\n      <td>119.000000</td>\n      <td>7.000000</td>\n      <td>1024.000000</td>\n      <td>58.000000</td>\n      <td>108.000000</td>\n      <td>2809.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>13.000000</td>\n      <td>218.000000</td>\n      <td>226.000000</td>\n      <td>1997.000000</td>\n      <td>143.000000</td>\n      <td>30.000000</td>\n      <td>1710.000000</td>\n      <td>127.000000</td>\n      <td>218.000000</td>\n      <td>2996.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>18.000000</td>\n      <td>231.000000</td>\n      <td>237.000000</td>\n      <td>3328.000000</td>\n      <td>168.000000</td>\n      <td>69.000000</td>\n      <td>2550.000000</td>\n      <td>260.000000</td>\n      <td>384.000000</td>\n      <td>3163.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>66.000000</td>\n      <td>254.000000</td>\n      <td>254.000000</td>\n      <td>7117.000000</td>\n      <td>254.000000</td>\n      <td>601.000000</td>\n      <td>7173.000000</td>\n      <td>360.000000</td>\n      <td>1397.000000</td>\n      <td>3858.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n# analyse exploratoire des données\n\nPour l'analyse exploratoire, nous allons utiliser qu'un échantillon des données.  Je vais en prendre 500\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nsample_size = 500 # Adjust this based on your dataset size\nX_sampled = X.sample(n=sample_size, random_state=42)\nY_sampled = Y.loc[X_sampled.index]\nX_sampled.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Slope</th>\n      <th>Hillshade_9am</th>\n      <th>Hillshade_Noon</th>\n      <th>Horizontal_Distance_To_Roadways</th>\n      <th>Hillshade_3pm</th>\n      <th>Vertical_Distance_To_Hydrology</th>\n      <th>Horizontal_Distance_To_Fire_Points</th>\n      <th>Aspect</th>\n      <th>Horizontal_Distance_To_Hydrology</th>\n      <th>Elevation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>500.000000</td>\n      <td>500.000000</td>\n      <td>500.000000</td>\n      <td>500.000000</td>\n      <td>500.000000</td>\n      <td>500.000000</td>\n      <td>500.00000</td>\n      <td>500.000000</td>\n      <td>500.000000</td>\n      <td>500.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>14.642000</td>\n      <td>211.054000</td>\n      <td>223.252000</td>\n      <td>2313.700000</td>\n      <td>143.338000</td>\n      <td>46.152000</td>\n      <td>1906.97800</td>\n      <td>155.922000</td>\n      <td>271.758000</td>\n      <td>2945.782000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>7.678265</td>\n      <td>28.780405</td>\n      <td>19.804366</td>\n      <td>1548.527391</td>\n      <td>40.718494</td>\n      <td>60.782744</td>\n      <td>1297.58581</td>\n      <td>111.414732</td>\n      <td>227.100543</td>\n      <td>290.643937</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>75.000000</td>\n      <td>149.000000</td>\n      <td>85.000000</td>\n      <td>0.000000</td>\n      <td>-152.000000</td>\n      <td>42.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1983.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>9.000000</td>\n      <td>197.000000</td>\n      <td>212.750000</td>\n      <td>1086.250000</td>\n      <td>119.000000</td>\n      <td>8.000000</td>\n      <td>982.75000</td>\n      <td>59.000000</td>\n      <td>108.000000</td>\n      <td>2805.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>13.000000</td>\n      <td>217.000000</td>\n      <td>226.000000</td>\n      <td>1945.500000</td>\n      <td>142.000000</td>\n      <td>29.000000</td>\n      <td>1642.50000</td>\n      <td>125.000000</td>\n      <td>212.000000</td>\n      <td>3001.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>19.000000</td>\n      <td>232.000000</td>\n      <td>237.000000</td>\n      <td>3226.250000</td>\n      <td>171.000000</td>\n      <td>67.000000</td>\n      <td>2411.25000</td>\n      <td>257.000000</td>\n      <td>376.750000</td>\n      <td>3149.250000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>42.000000</td>\n      <td>253.000000</td>\n      <td>254.000000</td>\n      <td>7078.000000</td>\n      <td>246.000000</td>\n      <td>387.000000</td>\n      <td>6576.00000</td>\n      <td>359.000000</td>\n      <td>1110.000000</td>\n      <td>3529.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nNous pouvons tracer la distribution de chaque variable.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\n_ = X_sampled.hist(figsize=(20, 14))\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-12-output-1.png){width=1545 height=1096}\n:::\n:::\n\n\nVoyons si on des dinausores dans les données.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nsns.pairplot(X_sampled)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-1.png){width=2357 height=2358}\n:::\n:::\n\n\nIl semble qu'il n'existe pas de corrélations linéaires entre les variables.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n# Correlation matrix\nimport seaborn as sns\ncorr_matrix = X_sampled.corr()\n\n# Heatmap of the correlation matrix\n\n_= sns.heatmap(corr_matrix, annot=True)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-14-output-1.png){width=770 height=634}\n:::\n:::\n\n\nCe graphique semble confirmer qu'il n'y a pas de corrélations linéaires entre les variables.\n\n## Box plot\n\nLe graphique ci-dessous montre la distribution de chaque variable en fonction de la variable cible.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n# box plot\n# Transformed Cover_Type to categorical\nY_sampled = Y_sampled.astype('category')\n\nfor col in X_sampled.columns:\n    sns.boxplot(x=Y_sampled, y=X_sampled[col])\n    plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-1.png){width=585 height=429}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-2.png){width=593 height=429}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-3.png){width=593 height=429}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-4.png){width=601 height=429}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-5.png){width=593 height=429}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-6.png){width=604 height=429}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-7.png){width=601 height=429}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-8.png){width=593 height=429}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-9.png){width=601 height=429}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-15-output-10.png){width=602 height=433}\n:::\n:::\n\n\nInterprétation: Nous allons nous concentrer sur la variable **Elevation**.\n\n On peut voir que la variable **Elevation** est très discriminante. \n\nLes types de couverture 1, 2, et 7 montrent des médianes relativement élevées pour l'élévation, avec 7 ayant la médiane la plus élevée, suivie par 1 et 2.\n\n# Chargement des données\nDataset2.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nwith open('Dataset2.csv', 'rb') as f:\n    result = chardet.detect(f.read())  # or readline if the file is large\n#print(result['encoding'])\n\nDataset2 = pd.read_csv('Dataset2.csv', delimiter=\",\",decimal = \".\",encoding=result['encoding'])\nDataset2.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 581012 entries, 0 to 581011\nData columns (total 2 columns):\n #   Column           Non-Null Count   Dtype\n---  ------           --------------   -----\n 0   Wilderness_Area  581012 non-null  int64\n 1   Soil_Type        581012 non-null  int64\ndtypes: int64(2)\nmemory usage: 8.9 MB\n```\n:::\n:::\n\n\nCette fois-ci, nous avons 2 variables et 581012 lignes.\nOn peut voir que les données sont de types int64 Inspectons ces données les pour voir si elles sont numériques ou catégorielles.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\n# Distribution de Y\nsns.countplot(x='Wilderness_Area', data=Dataset2)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-17-output-1.png){width=618 height=429}\n:::\n:::\n\n\nOn peut voir que la variable est catégorielle. Elle contient 4 classes équilibrées. Passons à la deuxième variable.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nsns.countplot(x='Soil_Type', data=Dataset2)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-18-output-1.png){width=620 height=431}\n:::\n:::\n\n\nIci, nous pouvons voir que la variable est plutôt numérique.  Traçons la distribution de la variable.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\n_=Dataset2[['Soil_Type']].hist(figsize=(20, 14))\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-19-output-1.png){width=1567 height=1096}\n:::\n:::\n\n\nComme les deux base de données,on les mêmes lignes, nous allons les concaténer.\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\ncombined_X = pd.concat([X, Dataset2], axis=1)\ncombined_X.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 581012 entries, 0 to 581011\nData columns (total 12 columns):\n #   Column                              Non-Null Count   Dtype\n---  ------                              --------------   -----\n 0   Slope                               581012 non-null  int64\n 1   Hillshade_9am                       581012 non-null  int64\n 2   Hillshade_Noon                      581012 non-null  int64\n 3   Horizontal_Distance_To_Roadways     581012 non-null  int64\n 4   Hillshade_3pm                       581012 non-null  int64\n 5   Vertical_Distance_To_Hydrology      581012 non-null  int64\n 6   Horizontal_Distance_To_Fire_Points  581012 non-null  int64\n 7   Aspect                              581012 non-null  int64\n 8   Horizontal_Distance_To_Hydrology    581012 non-null  int64\n 9   Elevation                           581012 non-null  int64\n 10  Wilderness_Area                     581012 non-null  int64\n 11  Soil_Type                           581012 non-null  int64\ndtypes: int64(12)\nmemory usage: 53.2 MB\n```\n:::\n:::\n\n\nNous pouvons maintenant séparer les données en train et test. Avec stratification sur la variable cible.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\n# split  data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(combined_X, Y, test_size=0.2, random_state=42, stratify=Y)\n```\n:::\n\n\nAvant de passer à la modélisation, nous allons standardiser les données,  et encoder les variables catégorielles.\n\nD'abord, nous allons séparer les variables numériques et catégorielles.\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nX_train.columns\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```\nIndex(['Slope', 'Hillshade_9am', 'Hillshade_Noon',\n       'Horizontal_Distance_To_Roadways', 'Hillshade_3pm',\n       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Fire_Points',\n       'Aspect', 'Horizontal_Distance_To_Hydrology', 'Elevation',\n       'Wilderness_Area', 'Soil_Type'],\n      dtype='object')\n```\n:::\n:::\n\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\ncategorical_cols = ['Wilderness_Area']\nnumerical_cols = ['Slope', 'Hillshade_9am', 'Hillshade_Noon',\n       'Horizontal_Distance_To_Roadways', 'Hillshade_3pm',\n       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Fire_Points',\n       'Aspect', 'Horizontal_Distance_To_Hydrology', 'Elevation', 'Soil_Type']\n```\n:::\n\n\nNous allons créer un pipeline pour standardiser les données numériques et encoder les variables catégorielles. J'adore les pipelines.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}