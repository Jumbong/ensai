{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Examen de machine learning\"\n",
        "author: \"Jumbong Junior\"\n",
        "date: \"2023-12-08\"\n",
        "categories: [news]\n",
        "---"
      ],
      "id": "b90129d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction\n",
        "\n",
        "Il est possible que ce soit Da Veiga qui assure vos cours, mais je vais vous offrir un aperçu de ce à quoi pourrait ressembler votre examen. C'est important, car nous avons tendance à sous-estimer ce type d'activité, surtout lorsqu'il autorise l'utilisation de générateurs de texte tels que ChatGPT. Cette année, peu d'étudiants ont achevé le projet, la charge de données étant longue et fastidieuse. Je vous conseille de vous y prendre en avance. Préparez des fonctions exécutant certaines tâches spécifiques, que je vous expliquerai progressivement.\n",
        "\n",
        "# Les données\n",
        "\n",
        "Les données, très larges proposées sont Dataset1 et Dataset2. Vous les trouverez\n",
        "sur mon [github]()\n",
        "# Packages\n",
        "\n",
        "J'utiliserai les packages suivants: sklearn, pandas, numpy, matplotlib,seaborn pour la visualiation. \n",
        "\n",
        "# Objectif\n",
        "\n",
        "L'objectif de ce notebook consistera à une 'analyse exploratoire des données, le prétraitement des données pour la modélisation, et l'application ainsi que l'évaluation de modèles de classification() sur un ensemble de données.\n"
      ],
      "id": "bc0bc9c8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Importation des packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import chardet\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n"
      ],
      "id": "7bc2ffba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chargement des données\n"
      ],
      "id": "9f9e9e14"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "with open('Dataset1.csv', 'rb') as f:\n",
        "    result = chardet.detect(f.read())  # or readline if the file is large\n",
        "#print(result['encoding'])\n",
        "\n",
        "Dataset1 = pd.read_csv('Dataset1.csv', delimiter=\",\",decimal = \".\",encoding=result['encoding'])\n",
        "Dataset1.head()"
      ],
      "id": "6c4d7751",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#info\n",
        "Dataset1.info()"
      ],
      "id": "eadf8e3f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les données contiennent 51 colonnes et 581012 lignes.\n",
        "Dans le code ci-dessous, nous allons séparer les données en output(Y) et en features(X). L'output ici est la variable **Cover_Type**.\n"
      ],
      "id": "c83c727d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        " # split  data into training and testing sets\n",
        "X = Dataset1.drop(['Cover_Type'], axis=1).copy()\n",
        "Y = Dataset1['Cover_Type'].copy()"
      ],
      "id": "f4300d39",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La prémiere chose à faire est de voir la distribution de Y. Afin de vérifier si c'est une variable catégorielle ou continue.\n"
      ],
      "id": "341e8288"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Distribution de Y\n",
        "sns.countplot(x='Cover_Type', data=Dataset1)\n",
        "plt.show()"
      ],
      "id": "7a8d6ebe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On peut voir que la variable est catégorielle. Elle contient 7 classes non équilibrées. On peut s'attendre que le modèle prédira mieux les classes les plus représentées(1 et 2) que les autres.\n",
        "\n",
        "Nous ne traiterons pas ça ici. Les données étant labélisées, nous allons utiliser des modèles de classification.\n",
        "\n",
        "# Data preprocessing\n",
        "\n",
        "Nous pouvons dans un premier temps vérifier s'il y a des valeurs manquantes dans les données.\n"
      ],
      "id": "95c68ea0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Missing values\n",
        "Dataset1.isnull().sum()"
      ],
      "id": "2829d450",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il n'y a pas de valeurs manquantes dans les données. \n",
        "\n",
        "# Features selections.\n",
        "\n",
        "Nous allons supprimer les variables en se basant sur le critère de [l'information mutulle](https://fr.wikipedia.org/wiki/Information_mutuelle) qui n'apportent pas au moins 0.01 d'information à la variable cible.\n",
        "\n",
        "En termes simples, l'information mutuelle mesure combien la connaissance d'une variable réduit l'incertitude concernant l'autre. \n"
      ],
      "id": "58a40167"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mutual_info = mutual_info_classif(X, Y)\n",
        "\n",
        "\n",
        "mutual_info_df = pd.DataFrame(mutual_info, index=X.columns, columns=['Mutual Information'])\n",
        "\n",
        "# Filtrer les caractéristiques avec une information mutuelle supérieure à 0.01\n",
        "relevant_features = mutual_info_df[mutual_info_df['Mutual Information'] > 0.01].index\n",
        "\n",
        "# Afficher les caractéristiques pertinentes\n",
        "print(\"Caractéristiques pertinentes (Information Mutuelle > 0.01) :\")\n",
        "print(relevant_features)"
      ],
      "id": "2b012738",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous allons supprimer les variables qui ne sont pas pertinentes.\n"
      ],
      "id": "39297082"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Supprimer les caractéristiques non pertinentes\n",
        "X = X[relevant_features]\n",
        "X.info()"
      ],
      "id": "d7d0c4d7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Là on a plus que 10 features et les données sont toutes numériques. \n"
      ],
      "id": "f94c14e3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X.describe()"
      ],
      "id": "7637318e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# analyse exploratoire des données\n",
        "\n",
        "Pour l'analyse exploratoire, nous allons utiliser qu'un échantillon des données.  Je vais en prendre 500\n"
      ],
      "id": "2afb9741"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sample_size = 500 # Adjust this based on your dataset size\n",
        "X_sampled = X.sample(n=sample_size, random_state=42)\n",
        "Y_sampled = Y.loc[X_sampled.index]\n",
        "X_sampled.describe()"
      ],
      "id": "d167bb3c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous pouvons tracer la distribution de chaque variable.\n"
      ],
      "id": "5c76fd28"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "_ = X_sampled.hist(figsize=(20, 14))"
      ],
      "id": "79e31751",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Voyons si on des dinausores dans les données.\n"
      ],
      "id": "21f5fbbb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.pairplot(X_sampled)"
      ],
      "id": "5c14e2ac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il semble qu'il n'existe pas de corrélations linéaires entre les variables.\n"
      ],
      "id": "7cbad986"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Correlation matrix\n",
        "import seaborn as sns\n",
        "corr_matrix = X_sampled.corr()\n",
        "\n",
        "# Heatmap of the correlation matrix\n",
        "\n",
        "_= sns.heatmap(corr_matrix, annot=True)"
      ],
      "id": "bc80fc0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ce graphique semble confirmer qu'il n'y a pas de corrélations linéaires entre les variables.\n",
        "\n",
        "## Box plot\n",
        "\n",
        "Le graphique ci-dessous montre la distribution de chaque variable en fonction de la variable cible.\n"
      ],
      "id": "6c406a66"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# box plot\n",
        "# Transformed Cover_Type to categorical\n",
        "Y_sampled = Y_sampled.astype('category')\n",
        "\n",
        "for col in X_sampled.columns:\n",
        "    sns.boxplot(x=Y_sampled, y=X_sampled[col])\n",
        "    plt.show()"
      ],
      "id": "7162bdfa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interprétation: Nous allons nous concentrer sur la variable **Elevation**.\n",
        "\n",
        " On peut voir que la variable **Elevation** est très discriminante. \n",
        "\n",
        "Les types de couverture 1, 2, et 7 montrent des médianes relativement élevées pour l'élévation, avec 7 ayant la médiane la plus élevée, suivie par 1 et 2.\n",
        "\n",
        "# Chargement des données\n",
        "Dataset2.\n"
      ],
      "id": "798fe8a3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "with open('Dataset2.csv', 'rb') as f:\n",
        "    result = chardet.detect(f.read())  # or readline if the file is large\n",
        "#print(result['encoding'])\n",
        "\n",
        "Dataset2 = pd.read_csv('Dataset2.csv', delimiter=\",\",decimal = \".\",encoding=result['encoding'])\n",
        "Dataset2.info()"
      ],
      "id": "89eb1081",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cette fois-ci, nous avons 2 variables et 581012 lignes.\n",
        "On peut voir que les données sont de types int64 Inspectons ces données les pour voir si elles sont numériques ou catégorielles.\n"
      ],
      "id": "f970edb7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Distribution de Y\n",
        "sns.countplot(x='Wilderness_Area', data=Dataset2)\n",
        "plt.show()"
      ],
      "id": "85a2dcf9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On peut voir que la variable est catégorielle. Elle contient 4 classes équilibrées. Passons à la deuxième variable.\n"
      ],
      "id": "789c3fb2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.countplot(x='Soil_Type', data=Dataset2)\n",
        "plt.show()"
      ],
      "id": "526bcaf0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ici, nous pouvons voir que la variable est plutôt numérique.  Traçons la distribution de la variable.\n"
      ],
      "id": "781aafd9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "_=Dataset2[['Soil_Type']].hist(figsize=(20, 14))"
      ],
      "id": "6ff6dc96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comme les deux base de données,on les mêmes lignes, nous allons les concaténer.\n"
      ],
      "id": "f3a797fd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "combined_X = pd.concat([X, Dataset2], axis=1)\n",
        "combined_X.info()"
      ],
      "id": "e3ff8619",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous pouvons maintenant séparer les données en train et test. Avec stratification sur la variable cible.\n"
      ],
      "id": "4613f7a7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# split  data into training and testing sets\n",
        "print(\"Splitting data into training and testing sets...\")\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(combined_X, Y, test_size=0.2, random_state=42, stratify=Y)"
      ],
      "id": "cb8431bd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Avant de passer à la modélisation, nous allons standardiser les données,  et encoder les variables catégorielles.\n",
        "\n",
        "D'abord, nous allons séparer les variables numériques et catégorielles.\n"
      ],
      "id": "35e14388"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train.columns"
      ],
      "id": "43485ae0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "categorical_cols = ['Wilderness_Area']\n",
        "numerical_cols = ['Slope', 'Hillshade_9am', 'Hillshade_Noon',\n",
        "       'Horizontal_Distance_To_Roadways', 'Hillshade_3pm',\n",
        "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Fire_Points',\n",
        "       'Aspect', 'Horizontal_Distance_To_Hydrology', 'Elevation', 'Soil_Type']"
      ],
      "id": "07d00fa1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous allons créer un pipeline pour standardiser les données numériques et encoder les variables catégorielles. J'adore les pipelines.\n"
      ],
      "id": "3c53f823"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),  # or median\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)])\n",
        "\n",
        "X_train_transformed = preprocessor.fit_transform(X_train)\n",
        "X_test_transformed = preprocessor.transform(X_test)"
      ],
      "id": "bcd62158",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ici nous n'avons pas de valeurs manquantes, mais nous avons quand même utilisé un imputer pour remplacer les valeurs manquantes par la moyenne pour les variables numériques et par la valeur la plus fréquente pour les variables catégorielles.\n",
        "Un premier pipeline pour les variables numériques et un deuxième pour les variables catégorielles. Nous avons utilisé un onehot encoder pour les variables catégorielles. Les données sont maintenant prêtes pour la modélisation.\n",
        "\n",
        "# Modélisation\n",
        "\n",
        "## Elastic Net Regression\n",
        "\n",
        "C'est une méthode de machine learning qui combine la régression Ridge et Lasso. Elle est utilisée pour résoudre le problème de surraprentissage, la multicollinéarité et la sélection de variables. \n",
        "\n",
        "Passons à sa modélisation :\n",
        "\n",
        "Nous avons utilisé ici un modèle de régression logistique avec une pénalité elasticnet. Nous avons utilisé une validation croisée pour trouver le meilleur paramètre de régularisation. Nous avons utilisé une pénalité elasticnet avec un ratio de 0.5. Nous avons utilisé un solver saga qui est adapté aux problèmes multiclasse. Nous avons utilisé une tolérance de 0.01. Nous avons utilisé un random state de 12345.\n"
      ],
      "id": "0da623c4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "clf_l1l2_LR = LogisticRegressionCV(penalty='elasticnet', l1_ratios=[0.5], \n",
        "                                   cv=5, multi_class=\"multinomial\", \n",
        "                                 solver=\"saga\",tol=0.01, random_state=12345)\n",
        "\n",
        "model = Pipeline(steps=[('preprocessor', preprocessor), ('logistic', clf_l1l2_LR)])\n",
        "\n",
        "model.fit(X_train,Y_train)\n",
        "prediction = model.predict(X_test)\n",
        "accuracy_LR = accuracy_score(Y_test, prediction)\n",
        "\n",
        "print(\"Accuracy of Logistic Regression :\",\"%.3f\" % accuracy_LR)"
      ],
      "id": "c170f3b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "J'ai un accuracy de 0.714. Ce n'est pas mal. Nous pouvons voir la matrice de confusion.\n"
      ],
      "id": "ce7eb2cb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Confusion matrix\n",
        "\n",
        "# Compute the confusion matrix\n",
        "conf_matrix = confusion_matrix(Y_test, prediction)\n",
        "\n",
        "# Display the confusion matrix using Seaborn's heatmap\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.show()"
      ],
      "id": "97865be7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Les valeurs sur la diagonale principale (de haut à gauche à bas à droite) représentent le nombre de prédictions correctes pour chaque classe. Par exemple, il y a 29724 prédictions correctes pour la classe 0, 44616 pour la classe 1, et ainsi de suite.\n",
        "- Les valeurs hors de la diagonale indiquent les erreurs de classification. Par exemple, 11947 instances de la classe 0 ont été incorrectement prédites comme appartenant à la classe 1.\n",
        "- La classe 0 a le plus grand nombre de faux positifs, c'est-à-dire que de nombreuses instances d'autres classes ont été incorrectement prédites comme appartenant à la classe 0.\n",
        "- Les classes avec le moins de prédictions incorrectes (et donc les plus sombres dans la visualisation) sont la classe 3 et la classe 6, avec respectivement 187 et 1993 prédictions correctes.\n",
        "Les cases avec un fond plus clair, en dehors de la diagonale, indiquent des erreurs moins fréquentes entre les classes spécifiques.\n",
        "\n",
        "## Random Forest\n",
        "\n",
        "### OOB error (Out-of-bag error)\n",
        "\n",
        "OOB est une méthode de validation croisée pour les forêts aléatoires. Chaque arbre dans la forêt est construit à partir d'un échantillon bootstrap du jeu de données d'entraînement. Certaines observations sont laissées de côté et non utilisées dans la construction d'un arbre donné. Ces observations \"hors sac\" peuvent être utilisées pour évaluer les performances de cet arbre. Du coup on peut utiliser cette méthode pour évaluer la performance de la forêt aléatoire et ajuster les hyperparamètres.\n",
        "\n",
        "Le code ci-dessous montre comment calculer l'erreur OOB pour un modèle de forêt aléatoire. Il permet en particulier de sélectionner la profondeur de l'arbre dans la forêt aléatoire.\n",
        "Le modèle de forêt aléatoire est entraîné avec une profondeur d'arbre de 10, 20 et 30. L'erreur OOB est calculée pour chaque modèle. Le modèle avec la plus petite erreur OOB est sélectionné.\n"
      ],
      "id": "f125e58e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Training Random Forest\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "depths = [10, 20, 30]\n",
        "oob_errors = []\n",
        "models = []\n",
        "best_oob_error = float('inf')\n",
        "best_model = None\n",
        "i = 0\n",
        "for depth in depths:\n",
        "    print(i)\n",
        "    model = RandomForestClassifier(max_depth=depth, oob_score=True, random_state=42,\n",
        "                                   n_estimators=100,  \n",
        "                                   warm_start=True  # This allows us to add more estimators later if needed\n",
        "                                  )\n",
        "    model.fit(X_train, Y_train)\n",
        "    oob_error = 1 - model.oob_score_\n",
        "    oob_errors.append(oob_error)\n",
        "    models.append(model)\n",
        "    if oob_error < best_oob_error:\n",
        "        best_oob_error = oob_error\n",
        "        best_model = model\n",
        "    i = i+1\n",
        "    print(\"Done\")\n",
        "\n",
        "# Print OOB errors for each model\n",
        "for depth, error in zip(depths, oob_errors):\n",
        "    print(f\"Depth: {depth}, OOB Error: {error}\")"
      ],
      "id": "c6c0590f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Accuracy et matrice de confusion\n"
      ],
      "id": "d75769bf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute the accuracy of the best random forest model\n",
        "predictions = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(Y_test, predictions)\n",
        "print(\"Accuracy of the Best Random Forest: {:.3f}\".format(accuracy))\n",
        "\n",
        "# Display the confusion matrix\n",
        "conf_matrix = confusion_matrix(Y_test, predictions)\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.show()"
      ],
      "id": "c4ea10d2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous avons un accuracy de 0.962. C'est très bien si on compare avec le modèle de régression logistique qui a un accuracy de 0.714. Nous pouvons voir la matrice de confusion.\n",
        "\n",
        "# Xgboost\n",
        "\n",
        "Essayons tout d'abord par expliquer ce qu'est le Xgboost. Xgboost signifie Extreme Gradient Boosting.\n",
        "Il combine des weaks models afin de produire des prédictions plus précises.  Il est très rapide et performant. \n",
        "\n",
        "Avant de passer à la modélisation, il faut transformer les données en un format spécifique à Xgboost.  En effet, le package xgboost ne gère pas les chaînes de caractères pour les étiquettes contrairement à tous les modèles entraînés précédemment, donc vous devez d'abord les encoder en tant qu'entiers.\n"
      ],
      "id": "fe3dd67d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# encode string class values as integers\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder = label_encoder.fit(Y)\n",
        "label_encoded_y_train = label_encoder.transform(Y_train)"
      ],
      "id": "0bf29269",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous avons utilisé un modèle de classification Xgboost avec les paramètres suivants:\n",
        "\n",
        "- objective='multi:softprob' : Spécifie la fonction objectif de l'entraînement. Ici, 'multi:softprob' est utilisé pour les problèmes de classification multiclasse et retournera une matrice de probabilité estimée pour chaque classe, ce qui est nécessaire pour calculer des scores comme le log-loss.\n",
        "\n",
        "- seed='12345' : Fournit une graine pour le générateur de nombres aléatoires. Cela garantit que les résultats sont reproductibles. Toutefois, il semble y avoir une petite confusion ici, car la graine devrait être un entier (seed=12345), pas une chaîne de caractères (seed='12345').\n",
        "\n",
        "- gamma=0 : Paramètre de régularisation qui minimise la complexité du modèle et aide à prévenir le surajustement. La valeur de 0 indique qu'il n'y a pas de régularisation supplémentaire.\n",
        "\n",
        "- learning_rate=0.05 : C'est le taux d'apprentissage, également connu sous le nom d'eta. Cela contribue à rendre le processus d'apprentissage plus robuste en empêchant les poids de s'ajuster trop fortement à chaque itération. Une valeur plus faible peut nécessiter plus d'arbres pour apprendre les mêmes relations, mais peut améliorer la performance finale du modèle.\n",
        "\n",
        "- max_depth=5 : Détermine la profondeur maximale de chaque arbre. C'est un autre paramètre qui aide à prévenir le surajustement. Plus la profondeur est grande, plus le modèle est complexe.\n",
        "\n",
        "- n_estimators=200 : Le nombre d'arbres à construire. Plus il y a d'arbres, plus le modèle peut être précis, mais cela augmente aussi le temps de calcul et le risque de surajustement.\n"
      ],
      "id": "f3680ad3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "clf_xgb = XGBClassifier(objective='multi:softprob', seed='12345',\n",
        "                       gamma=0, learning_rate=0.05, max_depth=5, n_estimators=200)\n",
        "clf_xgb.fit(X_train, label_encoded_y_train)\n",
        "\n",
        "accuracy_xgb = accuracy_score(label_encoder.transform(Y_test), clf_xgb.predict(X_test))\n",
        "\n",
        "print(\"Accuracy of XGBOOST :\",\"%.3f\" % accuracy_xgb)\n"
      ],
      "id": "34cc799d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ici on a un accuracy de 0.0.786. C'est mieux que le modèle de régression logistique mais moins bien que le modèle de forêt aléatoire. Nous pouvons voir la matrice de confusion.\n"
      ],
      "id": "6d79f2f7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Display the confusion matrix\n",
        "predictions = clf_xgb.predict(X_test)\n",
        "conf_matrix = confusion_matrix(Y_test, predictions)\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.show()"
      ],
      "id": "e62ccb1d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Courbe ROC\n",
        "\n",
        "La courbe ROC est un graphique qui montre la performance d'un modèle de classification à différents seuils de classification. Elle trace le taux de vrais positifs (TPR) en fonction du taux de faux positifs (FPR) à différents seuils de classification. Le TPR est également connu sous le nom de rappel et le FPR est égal à 1 - spécificité.\n"
      ],
      "id": "69d61772"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "def compute_roc_auc(models, X, Y_test):\n",
        "    \"\"\"\n",
        "    Compute ROC AUC for a list of models.\n",
        "    \n",
        "    Args:\n",
        "    models (dict): A dictionary of models with their names as keys.\n",
        "    X_test (array-like): Test features.\n",
        "    Y_test (array-like): True labels for the test set.\n",
        "    \n",
        "    Returns:\n",
        "    dict: A dictionary containing FPR, TPR, and ROC AUC for each model.\n",
        "    \"\"\"\n",
        "    Y_classes = np.unique(Y_test)\n",
        "    Y_test_binarized = label_binarize(Y_test, classes=Y_classes)\n",
        "    n_classes = len(Y_classes)\n",
        "    \n",
        "    results = {}\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        if model_name == 'Logistic':\n",
        "            model = Pipeline(steps=[('preprocessor', preprocessor), ('logistic', clf_l1l2_LR)])\n",
        "            model.fit(X_train,Y_train)\n",
        "            score = model.predict_proba(X_test)\n",
        "        else:\n",
        "          \n",
        "            score = model.predict_proba(X_test)\n",
        "        \n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "\n",
        "        # Compute ROC for each class\n",
        "        for i in range(n_classes):\n",
        "            fpr[i], tpr[i], _ = roc_curve(Y_test_binarized[:, i], score[:, i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "        # Compute micro-average ROC curve and ROC area\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test_binarized.ravel(), score.ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "        results[model_name] = {'fpr': fpr, 'tpr': tpr, 'roc_auc': roc_auc, 'score':score}\n",
        "\n",
        "    return results\n",
        "\n",
        "models = {\n",
        "    'Logistic': clf_l1l2_LR,\n",
        "      # Assurez-vous que clf_svm est entraîné sur des données mises à l'échelle si nécessaire\n",
        "    'Random Forests': best_model,\n",
        "    'XGBOOST': clf_xgb,\n",
        "    \n",
        "}\n",
        "\n",
        "roc_results = compute_roc_auc(models, X_test, Y_test)"
      ],
      "id": "735d4cbb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Ligne diagonale\n",
        "\n",
        "for model_name, metrics in roc_results.items():\n",
        "    plt.plot(metrics['fpr']['micro'], metrics['tpr']['micro'], label=f'{model_name} Micro (area = {metrics[\"roc_auc\"][\"micro\"]:.2f})')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title('Micro-Average Receiver Operating Characteristic')\n",
        "plt.show()"
      ],
      "id": "ac2f4420",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La courbe ROC montre que le modèle de forêt aléatoire est le meilleur modèle. Il a la plus grande surface sous la courbe (AUC). Le modèle Xgboost est le deuxième meilleur modèle. Le modèle de régression logistique est le moins bon modèle.\n",
        "\n",
        "# Bonus\n"
      ],
      "id": "51307ef0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Affichage des AUC micro-averaged\n",
        "print(\"Area under Roc Curve (micro-average) for:\\n\")\n",
        "for model_name in models.keys():\n",
        "    print(f\"- {model_name}: {roc_results[model_name]['roc_auc']['micro']:.3f}\")\n",
        "\n",
        "# Calcul et affichage des AUC one-vs-one macro-averaged\n",
        "print(\"\\nArea under Roc Curve (one-vs-one macro-average) for:\\n\")\n",
        "for model_name, model in models.items():\n",
        "    \n",
        "    score = roc_results[model_name]['score']\n",
        "    auc_ovo_macro = roc_auc_score(Y_test, score, multi_class=\"ovo\", average=\"macro\")\n",
        "    print(f\"- {model_name}: {auc_ovo_macro:.3f}\")"
      ],
      "id": "25a44c0b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion \n",
        "\n",
        "L'examen a couvert l'analyse, le prétraitement, la modélisation ML et l'évaluation, soulignant l'importance de sélectionner les caractéristiques et d'ajuster les hyperparamètres. Des techniques comme l'erreur OOB et la courbe ROC ont aidé à évaluer les modèles, avec une préparation minutieuse comme clé de la réussite."
      ],
      "id": "9e2cacdf"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}